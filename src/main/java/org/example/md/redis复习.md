### Redis 中常见的数据类型有哪些？（简单）

常见类型：

- String：字符串类型 （常用于做缓存、计数器（原子操作））。最大长度512M
- Hash：哈希类型（常用于存储对象，比如用户信息，商品信息）
- List：列表类型（常用于消息队列（简单任务调度），用户的操作的历史记录（快速访问））
- Set：集合类型（不可重复）（用于存储用户的兴趣标签 或则 某个页面多少个用户访问过）
- ZSet：有序集合类型（常用于排行榜，比如商品销量排行榜，用户积分排行榜）‘

其他类型：

- Bitmap：位图类型（常用于统计用户活跃状态，比如统计用户活跃天数）（占用空间少，只有0，1）
- HyperLogLog：基数统计类型（常用于统计用户数量，比如统计网站UV，PV） （概率性数据结构，估算）
- Geospatial：地理空间类型（常用于存储地理位置信息（经纬度），比如附近的人，附近商家（获取坐标））（计算距离）
- Stream：提供日志数据结构（存储时间序列数据或消息流）（消息队列）

### Redis 为什么这么快？（中等）

- 基于内存，内存读写速度比磁盘快很多，redis是存在内存中的（存储方式）
- 单线程，避免了多线程的上下文切换，避免了线程安全问题（线程模型）
- 高效的数据结构，有很多数据结构能在O(1)时间复杂度内完成数据写入
- IO多路复用，单线程处理多个客户端请求，通过事件驱动模型来处理请求（网络模型）
- 6.0后引入了多线程。减少网络I/O等待时间，利用CPU多核优势

#### select、poll、epoll的区别？

都是操作系统中多路复用I/O的机制：

- select：每次调用select，都会有个**固定长度数组**接收文件描述符，每次调用select都要重新构建和检查（1024大小）
- poll：select的升级版，没有固定长度数组，但是还需要遍历所有文件描述符，效率低
- epoll：select和poll的升级版，没有固定长度数组，提供边缘触发(ET)和水平触发（LT）模式，通过事件驱动模型来处理请求(
  只处理实际变化的数据)，效率高

### 为什么 Redis 设计为单线程？6.0 版本为何引入多线程？（中等）

- 单线程：减少了线程的上下文切换带来的性能开销
- redis的操作是基于内存的
- 在单线程下，使用I/O多路复用模型就可以提高redis的I/O利用率

为什么6.0需要引入多线程：因为随着数据变大，影响redis的是网络I/O。所以在网络I/O中引入多线程处理（键值读写是单线程的，多线程只针对网络请求，所以不会出现线程不安全情况）

- **I/O多路复用模型本质还是同步I/O**，用户需要等待数据拷贝到内存中才能获取，并发量高的话，这可能比较耗时（所以瓶颈在于网络I/O）

---

### Redis 中跳表的实现原理是什么？（困难）

**跳表**是一种**多链表**的数据结构，底层（level[0]层）保存了所有元素，每一层都是下一层的**子集**
插入：从最高层开始查找要插入的位置（先找到第一个比它大的元素），**随机**决定插入的层数，最后插入并更新指针
查找：从最高层开始查找要查找的位置，找到第一个比他大的元素后，再向下层找，依次类推，直到找到或遍历完，时间复杂度O(log n)
删除：从最高层开始查找要删除的位置，找到后删除并更新**各层指针**

**redis中跳表实现**

```c
typedef struct zskiplistNode {
    //Zset 对象的元素值
    sds ele;    // 主要用于存储数据
    //元素权重值
    double score;   // 分数
    //后退指针
    struct zskiplistNode *backward; // 指向当前节点的前一个节点
  
    //节点的level数组，保存每层上的前向指针和跨度
    struct zskiplistLevel {
        struct zskiplistNode *forward; // 指向当前节点下一层的节点
        unsigned long span; // 记录当前节点和下一个节点之间的距离（需要多少步才能走到下个节点）
    } level[];
} zskiplistNode;

```

**redis7.0插入元素 随机层数源码**

```c
以下源码来自 redis7.0

#define ZSKIPLIST_MAXLEVEL 32 /* Should be enough for 2^64 elements */
#define ZSKIPLIST_P 0.25   /* Skiplist P = 1/4 */

/* Returns a random level for the new skiplist node we are going to create.
 * The return value of this function is between 1 and ZSKIPLIST_MAXLEVEL
 * (both inclusive), with a powerlaw-alike distribution where higher
 * levels are less likely to be returned. */
int zslRandomLevel(void) {
    static const int threshold = ZSKIPLIST_P*RAND_MAX; // 0.25 * 最大值
    int level = 1; // 第一层开始，最底层是 0
    while (random() < threshold) // 随机
        level += 1;
    return (level<ZSKIPLIST_MAXLEVEL) ? level : ZSKIPLIST_MAXLEVEL;
}
```

### Redis 的 hash 是什么？ （中等）

hash 是一种**键值对**的数据结构，用于存储对象，比如用户信息，商品信息

基本操作：

```redis 
hset key field value
hget key field
hmset key field1 value1 field2 value2
hmget key field1 field2
hdel key field1 field2
-- increment 整数值，给 字段field + 个整数
hincrby key field increment
```

底层实现：

- redis6.0之前： ziplist(压缩列表) + hashtable(哈希表)
- redis7之后： listpack(紧凑列表) + hashtable(哈希表)，更换主要是解决ziplist的 级联更新 问题

上述两个列表存在两个值，一个为key默认512，值value默认64。例如：hash-max-ziplist-entries(512大小) ，hash-max-ziplist-value (
64大小)

- 当hash < key && hash < value，使用列表存储
- 当hash > key && hash > value，使用哈希表存储
- 默认值可以修改，且使用hashtable存储后不会退化

**hashtable代码：**

```c
// 
typedef struct dictht {
    //哈希表数组
    dictEntry **table; // 指向哈希表数组，数组中每个元素都是指向 dictEntry 的指针
    //哈希表大小
    unsigned long size;  
    //哈希表大小掩码，用于计算索引值
    unsigned long sizemask;  // sizemask = size - 1。用于计算索引，index = hash & sizemask
    //该哈希表已有的节点数量
    unsigned long used;
} dictht;

// 哈希数组结构体
typedef struct dictEntry {
    //键值对中的键
    void *key;
  
    //键值对中的值
    union {
        void *val;
        uint64_t u64;
        int64_t s64;
        double d;
    } v;
    //指向下一个哈希表节点，形成链表
    struct dictEntry *next;
} dictEntry;

```

#### 渐进式 rehash

**渐进式 rehash**：在rehash过程中，每次对hash表进行操作时，都会将hash表中的部分数据迁移到新的hash表中，而不是一次性迁移，避免阻塞redis
存在两个哈希表，可以分1表和2表，1表数据太大则向2表迁移数据（2表默认空表），扩容步骤

1. 创建一个比原hash表大2倍的hash表的2次方幂（结果是2次方幂且大于原表2倍）
2. rehashindx(索引值) 从 -1 变为 0 。每次增删改查都会将数据从1表迁到2表（插入直接插到2表）。然后rehashindx + 1
3. 重复步骤2，直到数据迁移完成，交换1，2表指针，设置rehashidx = -1

#### 扩容条件

**负载因子 = 哈希表已保存节点的数量 / 哈希表的大小**

1. 负载因子 > 1，没有RDB快照或AOF重写的持久化机制，就会rehash操作
2. 负载因子 > 5，无论有没有持久化机制，都会rehash操作
3. 负载因子 < 0.1，进行缩容（缩容为新表是原表的最近一个2次方幂） 1000 (old)-> 1024 (new)

### Redis ZSet 的实现原理是什么？（简单）

ZSet是一种有序集合，数据结构是 `跳表` + `哈希表`。常用于做排行榜，延迟队列，社交网络粉丝及关注数排序

1. 跳表：用于排序，快速查找
2. 哈希表：用于储存映射关系，快速查找

**元素较少则使用压缩列表ziplist,须同时满足两个条件：**

1. 元素个数 <= zset-max-ziplist-entries(默认128)
2. 元素成员们和分治长度 <= zset-max-ziplist-value(默认64)

---

### Redis 中如何保证缓存与数据库的数据一致性？（中等）

在对数据库进行增删改的时候改的时候，都要对缓存进行操作（可以是删除、或更新），但不推荐 更新缓存->更新数据库 , 更新数据库->
更新缓存， 删除缓存->更新数据库->后续查询回种到缓存。
以上三种都有可能导致数据不一致（当网络不稳定并发的时候）。
建议采用：**缓存双删策略**, 删除缓存->更新数据库->延迟删除缓存。
binlog异步更新缓存: 监听binlog变化（更新数据后），异步（可以是消息队列）更新缓存
实时一致性方案：先写MySQL再删缓存
最终一致性方案：Binlog + 消息队列 异步更新缓存

### Redis 中的缓存击穿、缓存穿透和缓存雪崩是什么？（中等）

**缓存击穿**：缓存中某个热点数据缓存失效，集中访问数据库，导致数据库奔溃
**缓存穿透**：缓存和数据库中都没有的数据（没有数据一直查数据），大量请求直接访问数据库，导致数据库奔溃
**缓存雪崩**：缓存中大量数据在同一时间失效，集中访问数据库，导致数据库奔溃

解决方法：

| 缓存击穿                            | 缓存穿透              | 缓存雪崩                       |
|---------------------------------|-------------------|----------------------------|
| 设置热点数据较长的过期时间（异步更新过期时间）         | 布隆过滤器             | 对缓存进行随机过期时间（在一定范围内随机）      |
| 使用互斥锁，确保同一时间只有一个请求可以去数据库查询并更新缓存 | 对空集也进行缓存（不存在数据缓存） | 双缓存策略（本地缓存+redis缓存等）       |
|                                 | 黑名单（封IP、账号等）      | 缓存预热（数据预热，可以定时任务先把数据更新到缓存） |
|                                 |                   | 服务熔断、构建redis集群             |

### Redis String 类型的底层实现是什么？（SDS）（中等）

String 底层是 sds （简单 动态 字符串）结构实现。并且结合了int，embstr，raw等不同编码进行优化

**c语言字符串缺陷:**

- 结尾为\0，表示字符串结束
- 获取长度需要遍历，时间复杂度为O(n)
- 字符串操作不高效，缓冲区溢出可能导致程序异常终止

---

### Redis 中如何实现分布式锁？ （中等）

使用set ex nx + lua脚本实现分布式锁。确保多个客户端不会获得同一个资源锁，也能安全解锁和意外情况下自动释放锁。

**注意事项：**

1. 锁一定要有过期时间
2. 锁在最后阶段一定要释放
3. 锁的过期时间要设置合理，避免锁过期后其他客户端无法获取锁

**单点故障问题**
**单台**redis在实现分布式锁存在的问题。在主从读写分离架构，如果主节点宕机，且宕机前已经给客户端上锁，因为主从复制的延迟
从节点还没有数据，这时候从节点晋升为主节点，并可以给其他客户端上锁，产生数据不一致。

**RedLock 红锁的出现**
RedLock 是一种分布式锁的实现方式，它通过在多个(通常为5个) Redis 实例上获取锁，来避免单点故障问题。
客户端只有在多个实例上加锁成功，则才算加锁成功。否则会释放已经加锁的实例，重新尝试

**RedLock 红锁的缺点**

1. 需要多个 Redis 实例，增加了系统的复杂性
2. 不适用于高并发（访问多个实例同时尝试获取锁，锁获取性能下降）
3. 需要确保redis实例的时间同步
4. 在长时间操作中可能需要手动续期锁，因为实例多，容易出错且复杂

### Redis 的 Red Lock 是什么？你了解吗？（中等）

在主从读写分离架构，如果主节点宕机，且宕机前已经给客户端上锁，因为主从复制的延迟
从节点还没有数据，这时候从节点晋升为主节点，并可以给其他客户端上锁，产生数据不一致。这时候就是RedLock出现的时候了, 

至少需要5个redis实例，加锁条件需要获取超过半数请求锁成功（为每个节点加锁时的超时时间应远小于锁的总过期时间），如果加锁失败需要对实例发送释放锁请求。


### Redis 实现分布式锁时可能遇到的问题有哪些？（中等）
1. 单点故障 （redis单机部署宕机，整个分布式锁将失效）
2. 主从数据不同 ： 在主从复制中，第一个主节点给客户端上锁后宕机，但数据还没同步到新晋升的主节点（原来的从节点），则他会给其他客户端上新锁，数据不一致
3. 业务未完成，锁却释放： 业务执行时间过长，锁过期，其他客户端可以获取锁
   - 需要合理设置过期时间
   - redisson 中存在看门狗机制 （会检测业务是否执行完成，未完成会自动续期，默认30秒，到20秒续期）。（类似心跳检测）
4. 网络分区问题：网络不稳定，导致连接不上，若未设置锁过期时间，则锁不会释放。设置多个锁可能会产生死锁
5. 时钟漂移： redis过期时间依赖实例的时间。时间不一致则会导致锁直接失效

---
### Redis 的持久化机制有哪些？（中等）
Redis 提供了两种持久化机制：RDB 和 AOF

RDB 是 Redis 的快照持久化机制，通过生成某一时刻的数据快照来实现持久化，适合做**灾难恢复**和**备份**（生成二进制文件）    
优点：
1. 生成快照时，不会影响 Redis 的正常读写操作（在主线程之外操作）
2. 占用空间小，生成的时压缩的二进制文件

缺点：
1. 数据丢失风险大，如果 Redis 宕机，可能会丢失从上次快照生成到宕机期间的数据

命令：`save`（同步，阻塞）(在主线程上执行);`bgsave`（异步，非阻塞）(默认方式) (fork一个子线程来执行RDB)

**bgsave执行流程：** 检查（查看是否有进行持久化操作，有则退出） -> 触发（触发持久化，调用rdbSaveBackground） ->
fork （fork子线程，子线程执行rdb） -> 写入临时文件（写入临时文件，最后替换原来的rdb，子线程退出）

AOF 是 Redis 的日志持久化机制，通过记录每一个写操作来保存数据，适合做**数据恢复**（数据更为精准，文件体积较大） 

优点：
1. 数据恢复更精准，记录了所有的redis执行的写命令

缺点：
1. 文件体积大，恢复速度慢

redis4.0新增RDB+AOF混合机制   
`aof-use-rdb-preamble`配置开启混合持久化。过程：     
1. 生成当前时间RDB快照，并写入新的AOF文件头部位置
2. 主线程这段时间的操作命令记录在**重写缓存区**（buf）
3. rdb写完后增量添加到 新的AOF 文件， 最后替换旧的AOF

#### AOF三种写回策略
1. always：每次写入操作都立即同步到磁盘，数据安全性最高，但性能最差
2. everysec：每秒同步一次，性能较好，数据安全性较高，但可能会丢失1秒内的数据
3. no：由操作系统决定何时同步，性能最好，但数据安全性最差，可能会丢失大量数据

#### AOF的重写机制
AOF 文件体积会随着时间增大，为了减小文件体积，Redis 提供了 AOF 重写机制，通过合并重复的写命令(只关心最新值)来减小文件体积。(写入的是新的AOF文件)


### Redis 主从复制的实现原理是什么？（中等）
Redis 主从复制是 Redis 提供的一种数据同步机制，用于实现数据在多个 Redis 实例之间的复制。主从复制的主要目的是提高 Redis 的可用性和数据一致性。    
主从复制的工作原理如下：    
全量同步：
1. 从节点向主节点发送 `PSYNC` 命令，请求同步数据。
2. 主节点收到 `PSYNC` 命令后，（没有runid值则为全量同步）还会传runid和offset（当前复制进度）,从节点存储
3. 执行 `BGSAVE` 命令生成 RDB 文件，RDB生成过程中，主节点写入到 `replication buffer`中（这个缓存空间个数对应从节点个数）
4. 生成好的RDB发给从节点，从节点清空旧数据加载RDB
5. 主节点将 `replication buffer` 中的数据发送给从节点（这是从节点在加载rdb时，主节点新增的数据），从节点执行命令

增量同步:
1. 从节点向主节点发送 `PSYNC` 命令，请求同步数据。
2. 判断是否有runid以及runid是否和主节点一致
3. 主节点中存在`repl_backlog_buffer`（环形缓冲区，大小1m，每次达到会覆盖旧数据，只有1个），查看这个缓冲区有没有offset的数据，有的话则进行增量同步
4. offset不存在，则证明数据被覆盖，进行全量同步

### Redis 数据过期后的删除策略是什么？（中等）
Redis 提供了多种数据过期后的删除策略，包括：
1. 定期删除：redis每隔一段时间（默认100ms）随机抽取一定数量的键，发现过期则删除。
    - 每次抽取20个key判断是否过期，占比超过25%再拉20个，小于25%则停止，删除时间不能超过25ms（如果查找时间已经超，则也会提前结束）
2. 惰性删除：在每次访问键时，检查键是否过期，如果过期则删除该键。（不访问不检查删除，可能会一致堆积）

redis还存在内存回收机制，里面有很多删除策略。一般对过期键处理方式为：惰性删除 + 定期删除。内存回收为兜底处理